{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475a4d8e",
   "metadata": {},
   "source": [
    "# Installation des dépendances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62c95a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from tqdm) (0.4.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\miniconda3\\envs\\torch310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio pandas pillow tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46286ea",
   "metadata": {},
   "source": [
    "# Chargement du dataset et des transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73a3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# Empêcher des crashs sur images corrompues\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        assert 'path' in self.df.columns and 'class_idx' in self.df.columns, \"Le CSV doit contenir 'path' et 'class_idx'\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_name = os.path.join(self.img_dir, row['path'])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        label = int(row['class_idx'])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transformations (Data Augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.15), ratio=(0.3, 3.3), value=\"random\")\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc408ff3",
   "metadata": {},
   "source": [
    "# Configuration des chemins et hyperparamètres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a580484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "torch.backends.mkldnn.enabled = False  # Évite des crashs CPU sous Windows\n",
    "\n",
    "class Config:\n",
    "    TRAIN_CSV = \"train_metadata.csv\"\n",
    "    SUB_CSV = \"sample_submission.csv\"\n",
    "    TRAIN_DIR = \"train_images\"\n",
    "    TEST_DIR = os.path.join(\"test_images\", \"mistery_cat\")\n",
    "\n",
    "    NUM_CLASSES = 20\n",
    "    BATCH_SIZE = 8\n",
    "    LR = 7e-4  # OneCycleLR max_lr\n",
    "    EPOCHS = 12  # plus d'epochs\n",
    "\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Limiter les threads pour réduire la contention CPU en notebooks\n",
    "try:\n",
    "    torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "def get_bird_model(num_classes):\n",
    "    # Modèle plus puissant: ConvNeXt-Tiny pré-entraîné\n",
    "    model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "\n",
    "    # Adapter la dernière couche\n",
    "    in_features = model.classifier[2].in_features\n",
    "    model.classifier[2] = nn.Sequential(\n",
    "        nn.Dropout(p=0.4),\n",
    "        nn.Linear(in_features, num_classes)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc12c2c",
   "metadata": {},
   "source": [
    "# Définition du modèle\n",
    "Utilise ConvNeXt-Tiny pré-entraîné et remplace la dernière couche pour 20 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ece2efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to C:\\Users\\Hp/.cache\\torch\\hub\\checkpoints\\convnext_tiny-983f1562.pth\n",
      "100%|██████████| 109M/109M [00:39<00:00, 2.89MB/s] \n",
      "Epoch 1/12: 100%|██████████| 109/109 [09:43<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc 9.36% | Val Acc: 20.74% | Loss: 2.9890\n",
      "Modèle sauvegardé !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/12: 100%|██████████| 109/109 [32:18<00:00, 17.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc 40.23% | Val Acc: 71.43% | Loss: 1.9889\n",
      "Modèle sauvegardé !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/12: 100%|██████████| 109/109 [32:49<00:00, 18.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc 56.76% | Val Acc: 46.08% | Loss: 1.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/12: 100%|██████████| 109/109 [35:12<00:00, 19.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc 47.75% | Val Acc: 58.06% | Loss: 1.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/12: 100%|██████████| 109/109 [34:57<00:00, 19.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc 52.25% | Val Acc: 61.29% | Loss: 1.5331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/12: 100%|██████████| 109/109 [36:49<00:00, 20.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc 51.33% | Val Acc: 77.42% | Loss: 1.3308\n",
      "Modèle sauvegardé !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/12: 100%|██████████| 109/109 [36:05<00:00, 19.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc 59.88% | Val Acc: 74.65% | Loss: 1.1579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/12: 100%|██████████| 109/109 [39:12<00:00, 21.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc 64.39% | Val Acc: 74.19% | Loss: 1.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/12: 100%|██████████| 109/109 [36:28<00:00, 20.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc 66.47% | Val Acc: 78.80% | Loss: 0.8951\n",
      "Modèle sauvegardé !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/12: 100%|██████████| 109/109 [34:32<00:00, 19.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc 70.40% | Val Acc: 83.87% | Loss: 0.8277\n",
      "Modèle sauvegardé !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/12: 100%|██████████| 109/109 [33:52<00:00, 18.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Acc 71.79% | Val Acc: 84.33% | Loss: 0.6647\n",
      "Modèle sauvegardé !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/12: 100%|██████████| 109/109 [33:07<00:00, 18.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Acc 76.76% | Val Acc: 85.25% | Loss: 0.7137\n",
      "Modèle sauvegardé !\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha <= 0:\n",
    "        return x, y, 1.0, y\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, lam, y_b\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1. Préparation des données\n",
    "    full_ds = BirdDataset(Config.TRAIN_CSV, Config.TRAIN_DIR, transform=train_transforms)\n",
    "    indices = list(range(len(full_ds)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "    # Compute class weights for WeightedRandomSampler\n",
    "    train_labels = [int(full_ds.df.iloc[i]['class_idx']) for i in train_idx]\n",
    "    class_counts = np.bincount(train_labels, minlength=Config.NUM_CLASSES)\n",
    "    class_weights = 1.0 / (class_counts + 1e-6)\n",
    "    sample_weights = [class_weights[label] for label in train_labels]\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "    # Windows/Jupyter: éviter les deadlocks -> num_workers=0\n",
    "    train_loader = DataLoader(\n",
    "        Subset(full_ds, train_idx),\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        sampler=sampler,\n",
    "        num_workers=0,\n",
    "        pin_memory=(Config.DEVICE == \"cuda\")\n",
    "    )\n",
    "    # Validation dataset with val_transforms\n",
    "    val_ds = BirdDataset(Config.TRAIN_CSV, Config.TRAIN_DIR, transform=val_transforms)\n",
    "    val_loader = DataLoader(\n",
    "        Subset(val_ds, val_idx),\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        num_workers=0,\n",
    "        pin_memory=(Config.DEVICE == \"cuda\")\n",
    "    )\n",
    "\n",
    "    # 2. Setup\n",
    "    model = get_bird_model(Config.NUM_CLASSES).to(Config.DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LR, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=Config.LR,\n",
    "        epochs=Config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader)\n",
    "    )\n",
    "\n",
    "    best_acc = 0\n",
    "\n",
    "    # Warmup: geler le backbone sur le premier epoch\n",
    "    def freeze_backbone(m):\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in m.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    def unfreeze_backbone(m):\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    # 3. Boucle d'entraînement\n",
    "    for epoch in range(Config.EPOCHS):\n",
    "        if epoch == 0:\n",
    "            freeze_backbone(model)\n",
    "        elif epoch == 1:\n",
    "            unfreeze_backbone(model)\n",
    "\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.EPOCHS}\"):\n",
    "            imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "\n",
    "            # MixUp with 50% probability\n",
    "            if np.random.rand() < 0.5:\n",
    "                imgs, y_a, lam, y_b = mixup_data(imgs, labels, alpha=0.2)\n",
    "            else:\n",
    "                y_a, lam, y_b = labels, 1.0, labels\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = lam * criterion(outputs, y_a) + (1 - lam) * criterion(outputs, y_b)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            _, pred = outputs.max(1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        train_acc = 100.0 * correct / total if total else 0.0\n",
    "        avg_loss = running_loss / total if total else 0.0\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
    "                out = model(imgs)\n",
    "                val_pred = out.max(1)[1]\n",
    "                val_correct += val_pred.eq(labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        acc = 100.0 * val_correct / val_total if val_total else 0.0\n",
    "        print(f\"Epoch {epoch+1}: Train Acc {train_acc:.2f}% | Val Acc: {acc:.2f}% | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), \"best_bird_model.pth\")\n",
    "            print(\"Modèle sauvegardé !\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d784a71",
   "metadata": {},
   "source": [
    "# Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7971c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_9520\\3844017890.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"best_bird_model.pth\", map_location=Config.DEVICE)\n",
      "100%|██████████| 400/400 [39:32<00:00,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier submission.csv généré !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "\n",
    "# Inference helper to convert PIL crops into normalized tensors\n",
    "_infer_transform = None\n",
    "\n",
    "def _ensure_infer_transform():\n",
    "    global _infer_transform\n",
    "    if _infer_transform is None:\n",
    "        from torchvision import transforms\n",
    "        _infer_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    return _infer_transform\n",
    "\n",
    "\n",
    "def predict():\n",
    "    model = get_bird_model(Config.NUM_CLASSES).to(Config.DEVICE)\n",
    "    state = torch.load(\"best_bird_model.pth\", map_location=Config.DEVICE)\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "\n",
    "    sub_df = pd.read_csv(Config.SUB_CSV)\n",
    "    preds = []\n",
    "    infer_tf = _ensure_infer_transform()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_name in tqdm(sub_df['path']):\n",
    "            path = os.path.join(Config.TEST_DIR, img_name)\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "\n",
    "            # Resize une fois, puis multi-crop et flip horizontal, moyenne des logits\n",
    "            img_r = TF.resize(img, [256, 256])\n",
    "            crops = list(TF.five_crop(img_r, 224))  \n",
    "            flips = [TF.hflip(c) for c in crops]\n",
    "            all_views = crops + flips\n",
    "\n",
    "            tensors = [infer_tf(c) for c in all_views]\n",
    "            batch = torch.stack(tensors).to(Config.DEVICE)\n",
    "\n",
    "            out = model(batch).mean(0)\n",
    "            preds.append(out.argmax().item())\n",
    "\n",
    "    sub_df['class_idx'] = preds\n",
    "    sub_df.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Fichier submission.csv généré !\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch310)",
   "language": "python",
   "name": "torch310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
